{
  
    
        "post0": {
            "title": "Feature Extraction & Style Transfer",
            "content": "Neural style transfer is a method to combine two images together, the content of one and the art/style of the other. Building up on the previous guide I published regarding visualizing features from a cnn, we will use the feature extractor (slightly modified) as we do not want to display the image. . The idea here is to start with a generated picture which is a copy of the original picture you wish to transform, compute its content loss with the original picture, compute its art loss with the artistic image, update the weights of the image generated to reduce the loss of a linear combination of the two losses. . import torch.nn as nn import os from pathlib import Path from PIL import Image from numpy import asarray from torchvision import transforms import matplotlib.pyplot as plt from torch.utils.data import Dataset, DataLoader import torchvision.models as models import torch . . vgg = models.vgg19(pretrained=True) device = torch.device( &quot;cuda&quot; if (torch.cuda.is_available()) else &#39;cpu&#39;) . class FeatureExtractor(nn.Module): def __init__(self, model, blocks): super().__init__() self.features = model.features self.blocks = blocks def forward(self, x): features = [] for n, layer in enumerate(self.features): x = layer(x) if n in self.blocks: features.append(x) return features . f = FeatureExtractor(vgg, [0, 5, 10, 19, 28]) . Loss . We define the loss to be a linear combination of the content loss and style loss. $$Loss = alpha * contentLoss + beta * styleLoss $$ . where $ alpha$ &amp; $ beta$ are positive entities . we can use MSE for the content loss, we traying to see the difference between the original features extarcted and the ones from the generaped pic for content loss generated at channel $l$: $$ ContentLoss_l(gen, ori) = frac{1}{2} sum_{i,j} (gen_{i,j,l} - ori_{i, j, l})^2$$ . def content_loss(generated_features, original_features): return ((generated_features - original_features) ** 2).mean() . for the style loss, we will calculate the gram matrix for for the genarted features which will give us the correlation between channels/filters response. we will also do tyhe same for the style. The loss at a layer l is: $$E_l = frac{1}{4N_l^2M_l^2} sum_{i,j}(G_{i,j}^l - A_{i,j}^l)^2 $$ l, Nₗ and Mₗ are the numbers of channels and height and width in the feature representation of layer l. . to get the loss at all layers, we do MSE across all layers . def style_loss(generated, style): batch_size, channel, h, w=gen.shape G = torch.mm(generated.view(channel, h * w), generated.view(channel, h * w).t()) A = torch.mm(style.view(channel, h * w), style.view(channel, h * w).t()) return ((G-A) ** 2).mean() . Back to our original formula: $$Loss = alpha * contentLoss + beta * styleLoss $$ . def loss(generated_features, original_features, style_featues, alpha, beta): s_loss, c_loss = 0, 0 for gen, cont, style in zip(generated_features, original_features, style_featues): c_loss += content_loss(gen, cont) s_loss += style_loss(gen, style) total_loss = alpha * c_loss + beta * s_loss return total_loss . Now let&#39;s attempt to transfer the art of Van gogh&#39;s paiting &#39;The Starry Night&#39; into a regular picture taken at south of france . dic = Path(&#39;van&#39;) original_path = dic/&#39;france.jpg&#39; style_path = dic/&#39;van.jpg&#39; _, axes = plt.subplots(1, 2) axes[0].imshow(Image.open(original_path)) axes[1].imshow(Image.open(style_path)) . . &lt;matplotlib.image.AxesImage at 0x193e2c7fd30&gt; . feature_extractor = f.to(device).eval() # or set all parameteres to grad requires false to save memory def read_image(path): img = Image.open(path) trans = transforms.Compose([transforms.Resize((512,512)), transforms.ToTensor()]) data = trans(img) return data.to(device, torch.float).unsqueeze(0) #initialize the paramerters required for fitting the model original_image = read_image(original_path) style_image = read_image(style_path) #using adam optimizer and it will update the generated image not the model parameter . We have defined above a way to read image and make necessary transformations before being fed to a model, lets train our train method below transfer_style. . For the optimizer, the weights targeted are for the image generated, we wish to update the weights of our original image such that the content loss and style loss are minimized given the hyparmeters $ alpha$ and $ beta$. . from torchvision.utils import save_image shape = transforms.ToTensor()(Image.open(original_path)).shape lr=0.01 alpha=8 beta=70 def transfer_style(model, original_image, style_image, epoch=5000): generated_image = original_image.clone().requires_grad_(True) optimizer = torch.optim.Adam([generated_image],lr=lr) images = [] for e in range (epoch): #extract original features, generated features &amp; style features to compute loss # original and generated for content loss, geenrated and style for style loss original_features = model(original_image) generated_features = model(generated_image) style_features = model(style_image) total_loss = calculate_loss(generated_features, original_features, style_features, alpha, beta) optimizer.zero_grad() total_loss.backward() optimizer.step() if(e % 100 == 0): images.append(transforms.ToPILImage() (transforms.Resize(shape[-2:])(generated_image.squeeze(0)))) #save_image(transforms.Resize(shape[-2:])(generated_image), dic/&#39;output&#39;/f&#39;gen{e//100}.png&#39;) return images . m = transfer_style(feature_extractor, original_image, style_image) #original_image.shape . _, axes = plt.subplots(1, 3, figsize=(20, 60)) axes[0].imshow(m[0]) axes[1].imshow(m[4]) axes[2].imshow(m[-1]) . . &lt;matplotlib.image.AxesImage at 0x193dbff96a0&gt; . Conclusion . We have applied neural style transfer, to get different effects, we could play around with $ alpha$ and $ beta$, the number of epochs and the input images of course. . Our training loop looks very similar to a normal training loop however we are not training the model, we are just using its feature part to get extract the features from the images. the loss then is computed and backpropagation is performed which updates the weight of the generated picture . resources . A Neural Algorithm of Artistic Style .",
            "url": "https://yassine-mhedhbi.github.io/YassBlog/cnn/jupyter/vgg/transfer%20learning/style%20transfer/2020/12/13/Feature-Extraction-&-Style-Transfer.html",
            "relUrl": "/cnn/jupyter/vgg/transfer%20learning/style%20transfer/2020/12/13/Feature-Extraction-&-Style-Transfer.html",
            "date": " • Dec 13, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Visualizing CNN features",
            "content": "Chances you have heard of CNNs before and how they are used in computer vision. A traditional multilayer Perceptrons do not take advantage of the importance of locality of pixel dependencies, instead, it flattens the images and sort of treats them as tabular data. We have come a long way since then. . A brief recap of convolutions . in theory, a convolution at x tires to measure the overlap between two functions in a specified bound where one is flipped and shifted by x . $$(f*g)(x) = int f(z)g(x-z) ; dz $$ . However, when dealing with images, they are discrete objects (the pixels) hence the integral can be simplified into a sum and for a two-dimension tensor: . $$(f*g)(i,j) = sum_a sum_b f(a,b)g(i-a, j-b) $$ . from IPython.display import Image, display display(Image(&#39;ghtop_images/conv.png&#39;)) . . so feature[0,0] = 2 x 1 + 4 x 2 + 3 x 9 + 2 x (-4) + 1 x 7 + 4 x 4 + 1 x 2 + 1 x (-5) + 2 x 1 = 51 . a kernel, which also can be called a filter, tries to highlight or find a pattern in the image. In a complex deep learning model, the parameters of these filters cannot realistically be set manually or which filter should do what, instead, We just try to find a suitable architecture and hope we can learn the kernels . Extracting Features . We can attempt to extract features from known architectures, a simple one from Vgg (Visual Geometry Group) using blocks. First, we import the pre-trained module, by default Vgg16 output is designed for 1000, we can add a linear layer and try to train only that layer which is shown below. We only need to set the imported parameters to be unlearnable and use our regular learning method . import torchvision.models as models vgg16 = models.vgg16(pretrained=True).cuda() . import torch.nn as nn class MyVgg16(nn.Module): def __init__(self): self.vgg16 = models.vgg16(pretrained=True).cuda() self.fc = nn.Linear(1000, 10) for p in self.vgg16.parameters(): p.requires_grad = False def forward(self, x): x = self.vgg16(x) x = self.fc(x) . Dataset . I&#39;m using this kaggle dataset which contains images for 10 different animal species, let&#39;s try to take a look at the animals . from pathlib import Path from data.translate import translate from PIL import Image from torchvision import transforms import matplotlib.pyplot as plt import os . . path = Path(&#39;data/raw-img&#39;) classes = os.listdir(path) # in spanish classes_en = list(map(lambda class_sp: translate[class_sp], classes)) # translate to english def read_image(path, cl): img = Image.open(path) data = transforms.ToTensor()(img) return data, cl # Get an images of each class examples = [] for cl in classes: #print(len(os.listdir(path/cl)), translate[cl]) p = str(path/cl/os.listdir(path/cl)[0]) data = read_image(p, cl) examples.append(data[0]) _, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 6)) axes = axes.flatten() for i, (ax, img) in enumerate(zip(axes, examples)): ax.imshow(transforms.ToPILImage()(img)) ax.set_title(translate[classes[i]]) ax.axes.get_xaxis().set_visible(False) ax.axes.get_yaxis().set_visible(False) . from torch.utils.data import Dataset, DataLoader class AnimalDataset(Dataset): def __init__(self, path): self.classes = os.listdir(path) self.images = [] for i, cl in enumerate(self.classes): self.images.extend(list(map(lambda x: (path/cl/x, i), os.listdir(path/cl)))) def __len__(self): return len(self.images) def __getitem__(self, idx): path, label = self.images[idx] X = self._read_image(path) X = transforms.Resize((224, 224))(X) return X, label def _read_image(self, path): img = Image.open(path).convert(&#39;RGB&#39;) data = transforms.ToTensor()(img) return data . Next we create our feature extractor, we can specify the blocks input which is a list of all the block features we want. . class Vgg16FeatureExtractor(nn.Module): def __init__(self, model, blocks): super().__init__() self.features = model.features self.blocks = blocks def forward(self, image, block=1, subplots=(2, 10)): data, y = image print(translate[dt.classes[y[0]]]) plt.imshow(transforms.ToPILImage()(data[0])) features = [] print(f&#39;extracting feature from block {block}&#39;) channels = subplots[0] * subplots[1] _, axes = plt.subplots(*subplots, figsize=(15, 5)) axes = axes.flatten() for channel, ax in enumerate(axes): im = self.features[:self.blocks[block]](data.cuda())[0][channel] features.append(im) im = transforms.ToPILImage()(im).resize((200, 200)) ax.imshow(im) ax.set_title(f&#39;channel {channel+1}&#39;) ax.axes.get_xaxis().set_visible(False) ax.axes.get_yaxis().set_visible(False) return features . path = Path(&#39;data/raw-img&#39;) dt = AnimalDataset(path) examples = iter(DataLoader(dt, batch_size=1, shuffle=True)) . feature_extractor = Vgg16FeatureExtractor(model=vgg16, blocks=[0, 5, 10, 19, 28]) example = next(examples) . features = feature_extractor.forward(example, subplots=(1, 10)) . chicken extracting feature from block 1 . features = feature_extractor.forward(example, block = 2, subplots=(1, 10)) . chicken extracting feature from block 2 . f = feature_extractor.forward(example, block = 4, subplots=(1, 10)) . chicken extracting feature from block 4 . example = next(examples) _ = feature_extractor.forward(example, block= 1, subplots=(2, 10)) . elephant extracting feature from block 1 . example = next(examples) _ = feature_extractor.forward(example, block = 2, subplots=(3, 10)) . dog extracting feature from block 2 . example = next(examples) _ = feature_extractor.forward(example, block = 1, subplots=(1, 5)) . spider extracting feature from block 1 . Conclusion . Hopefully this provides you an idea with how features that are being fed to a classifier look like. We have used VGG16 due to its simple architecture, also we are only showing the first channels given the subplot value. That being said, not every CNN model has a clear architecture that can be easily decomposed as as feature extractor and a classifier however it is achievable. . I hope this excites you about Computer vision as it did to me when I first came across this, in the next post, we will build on the idea of feature extracting to transfer the art and style to another picture .",
            "url": "https://yassine-mhedhbi.github.io/YassBlog/cnn/jupyter/vgg/transfer%20learning/2020/12/09/Visualize-CNN-Features.html",
            "relUrl": "/cnn/jupyter/vgg/transfer%20learning/2020/12/09/Visualize-CNN-Features.html",
            "date": " • Dec 9, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Scraping CIA Data [Tutorial]",
            "content": "We are interested in the CIA factbook data which is located here (Please note this may have changed since 2020), I have downloaded the report from here and step by step we will read the data, clean it and presented in structured manner . import pandas as pd import numpy as np import statsmodels.api as sm import matplotlib.pyplot as plt from bs4 import BeautifulSoup from IPython import display import os import re import seaborn as sns; sns.set() %matplotlib inline . Scraping CIA Factbook . cat = &#39;CIA data/docs/notesanddefs.html&#39; page = open(cat).read() page = BeautifulSoup(page) data_map = {} cols = page.select(&quot;div.category&quot;) for col in cols: links = col.select(&#39;a&#39;) if len(links) &gt; 0: fpath = links[0][&#39;href&#39;] field = col.text.strip() data_map[field] = fpath print(field, fpath) . Administrative divisions ../fields/302.html Age structure ../fields/341.html Agriculture - products ../fields/215.html Airports ../fields/379.html Airports - with paved runways ../fields/380.html Airports - with unpaved runways ../fields/381.html Area ../fields/279.html Area - comparative ../fields/280.html Background ../fields/325.html Birth rate ../fields/345.html Broadband - fixed subscriptions ../fields/206.html Broadcast media ../fields/199.html Budget ../fields/224.html Budget surplus (+) or deficit (-) ../fields/226.html Capital ../fields/301.html Carbon dioxide emissions from consumption of energy ../fields/274.html Central bank discount rate ../fields/230.html Children under the age of 5 years underweight ../fields/368.html Citizenship ../fields/310.html Civil aircraft registration country code prefix ../fields/378.html Climate ../fields/284.html Coastline ../fields/282.html Commercial bank prime lending rate ../fields/231.html Communications - note ../fields/205.html Constitution ../fields/307.html Contraceptive prevalence rate ../fields/357.html Country name ../fields/296.html Crude oil - exports ../fields/262.html Crude oil - imports ../fields/263.html Crude oil - production ../fields/261.html Crude oil - proved reserves ../fields/264.html Current account balance ../fields/238.html Death rate ../fields/346.html Debt - external ../fields/246.html Demographic profile ../fields/340.html Dependency ratios ../fields/342.html Dependency status ../fields/298.html Dependent areas ../fields/304.html Diplomatic representation from the US ../fields/319.html Diplomatic representation in the US ../fields/318.html Disputes - international ../fields/326.html Distribution of family income - Gini index ../fields/223.html Drinking water source ../fields/361.html Economy - overview ../fields/207.html Education expenditures ../fields/369.html Electricity - consumption ../fields/253.html Electricity - exports ../fields/254.html Electricity - from fossil fuels ../fields/257.html Electricity - from hydroelectric plants ../fields/259.html Electricity - from nuclear fuels ../fields/258.html Electricity - from other renewable sources ../fields/260.html Electricity - imports ../fields/255.html Electricity - installed generating capacity ../fields/256.html Electricity - production ../fields/252.html Electricity access ../fields/251.html Elevation ../fields/286.html Environment - current issues ../fields/293.html Environment - international agreements ../fields/294.html Ethnic groups ../fields/400.html Exchange rates ../fields/249.html Executive branch ../fields/312.html Exports ../fields/239.html Exports - commodities ../fields/240.html Exports - partners ../fields/241.html Fiscal year ../fields/228.html Flag description ../fields/320.html GDP (official exchange rate) ../fields/209.html GDP (purchasing power parity) ../fields/208.html GDP - composition, by end use ../fields/213.html GDP - composition, by sector of origin ../fields/214.html GDP - per capita (PPP) ../fields/211.html GDP - real growth rate ../fields/210.html Geographic coordinates ../fields/277.html Geography - note ../fields/295.html Government - note ../fields/323.html Government type ../fields/299.html Gross national saving ../fields/212.html Health expenditures ../fields/358.html Heliports ../fields/382.html HIV/AIDS - adult prevalence rate ../fields/363.html HIV/AIDS - deaths ../fields/365.html HIV/AIDS - people living with HIV/AIDS ../fields/364.html Hospital bed density ../fields/360.html Household income or consumption by percentage share ../fields/222.html Illicit drugs ../fields/329.html Imports ../fields/242.html Imports - commodities ../fields/243.html Imports - partners ../fields/403.html Independence ../fields/305.html Industrial production growth rate ../fields/217.html Industries ../fields/216.html Infant mortality rate ../fields/354.html Inflation rate (consumer prices) ../fields/229.html International law organization participation ../fields/309.html International organization participation ../fields/317.html Internet country code ../fields/202.html Internet users ../fields/204.html Irrigated land ../fields/289.html Judicial branch ../fields/314.html Labor force ../fields/218.html Labor force - by occupation ../fields/219.html Land boundaries ../fields/281.html Land use ../fields/288.html Languages ../fields/402.html Legal system ../fields/308.html Legislative branch ../fields/313.html Life expectancy at birth ../fields/355.html Literacy ../fields/370.html Location ../fields/276.html Major infectious diseases ../fields/366.html Major urban areas - population ../fields/350.html Map references ../fields/278.html Maritime claims ../fields/283.html Maritime threats ../fields/334.html Market value of publicly traded shares ../fields/237.html Maternal mortality rate ../fields/353.html Median age ../fields/343.html Merchant marine ../fields/387.html Military - note ../fields/332.html Military branches ../fields/331.html Military expenditures ../fields/330.html Military service age and obligation ../fields/333.html Mother&#39;s mean age at first birth ../fields/352.html National air transport system ../fields/377.html National anthem ../fields/322.html National holiday ../fields/306.html National symbol(s) ../fields/321.html Nationality ../fields/336.html Natural gas - consumption ../fields/270.html Natural gas - exports ../fields/271.html Natural gas - imports ../fields/272.html Natural gas - production ../fields/269.html Natural gas - proved reserves ../fields/273.html Natural hazards ../fields/292.html Natural resources ../fields/287.html Net migration rate ../fields/347.html Obesity - adult prevalence rate ../fields/367.html People - note ../fields/374.html Physicians density ../fields/359.html Pipelines ../fields/383.html Political parties and leaders ../fields/315.html Population ../fields/335.html Population below poverty line ../fields/221.html Population distribution ../fields/348.html Population growth rate ../fields/344.html Ports and terminals ../fields/388.html Public debt ../fields/227.html Railways ../fields/384.html Refined petroleum products - consumption ../fields/266.html Refined petroleum products - exports ../fields/267.html Refined petroleum products - imports ../fields/268.html Refined petroleum products - production ../fields/265.html Refugees and internally displaced persons ../fields/327.html Religions ../fields/401.html Reserves of foreign exchange and gold ../fields/245.html Roadways ../fields/385.html Sanitation facility access ../fields/398.html School life expectancy (primary to tertiary education) ../fields/371.html Sex ratio ../fields/351.html Stock of broad money ../fields/235.html Stock of direct foreign investment - abroad ../fields/248.html Stock of direct foreign investment - at home ../fields/247.html Stock of domestic credit ../fields/236.html Stock of narrow money ../fields/234.html Suffrage ../fields/311.html Taxes and other revenues ../fields/225.html Telephone system ../fields/198.html Telephones - fixed lines ../fields/196.html Telephones - mobile cellular ../fields/197.html Terrain ../fields/285.html Terrorist groups - foreign based ../fields/396.html Terrorist groups - home based ../fields/397.html Total fertility rate ../fields/356.html Trafficking in persons ../fields/328.html Transportation - note ../fields/389.html Unemployment rate ../fields/220.html Unemployment, youth ages 15-24 ../fields/373.html Urbanization ../fields/349.html Waterways ../fields/386.html . So these are all the fields in the report, we will try now to map each field to its data while also keeping track of the country . def map_data(data_map): data = {} for field in data_map: page = open(&#39;CIA data/fields/&#39; + data_map[field].split(&#39;/&#39;)[-1]).read() page_field = BeautifulSoup(page) cols = page_field.select(&#39;td&#39;) for i in range(len(cols)): if i % 2 == 0: country = cols[i].select(&#39;a&#39;)[0].text else: value = cols[i].select(&#39;div.category_data&#39;) if field not in data: data[field] = [(country, [x.text for x in value])] else: data[field].append((country, [x.text for x in value])) return data data = map_data(data_map) . Demographics and Constructing a data Frame . We will start first with the demographics and answer general questions about each country, below are the columns of interest . Columns = [&#39;Age structure&#39;, &#39;Area&#39;,&#39;Budget&#39;, &#39;Birth rate&#39;, &#39;Death rate&#39;, &#39;Debt - external&#39;, &#39;GDP (official exchange rate)&#39;, &#39;GDP - per capita (PPP)&#39;, &#39;Hospital bed density&#39;,&#39;Physicians density&#39;, &#39;Life expectancy at birth&#39;, &#39;Household income or consumption by percentage share&#39;, &#39;Population&#39;, &#39;Population below poverty line&#39;, &#39;Religions&#39;, &#39;Unemployment rate&#39;, &#39;Median age&#39;] . from functools import reduce dfList = [] for field in Columns: df = pd.DataFrame({&#39;Country&#39;: [key[0] for key in data[field]], field: [ key[1] for key in data[field]]}) dfList.append(df) df = reduce(lambda x, y: pd.merge(x, y, how=&#39;outer&#39;, on = &#39;Country&#39;), dfList) . df.head() . Country Age structure Area Budget Birth rate Death rate Debt - external GDP (official exchange rate) GDP - per capita (PPP) Hospital bed density Physicians density Life expectancy at birth Household income or consumption by percentage share Population Population below poverty line Religions Unemployment rate Median age . 0 | Afghanistan | [ n0-14 years: n40.92% n(male 7,263,716 /femal... | [ ntotal: n652,230 sq km n n, nland: n652,230... | [ nrevenues: n2.276 billion n n(2017 est.) n, ... | [ n37.5 births/1,000 population n n(2018 est.) n] | [ n13.2 deaths/1,000 population n n(2018 est.) n] | [ n$2.84 billion n n(FY/) n] | [ n$20.24 billion n(2017 est.) n(2017 est.) n] | [ n$2,000 n n(2017 est.) n, n$2,000 n n(2016 ... | [ n0.5 beds/1,000 population n n(2014) n] | [ n0.3 physicians/1,000 population n n(2016) n] | [ ntotal population: n52.1 years n n(2018 est.... | [ nlowest 10%: n3.8% n n(2008) n, nhighest 10... | [ n34,940,837 n n(July 2018 est.) n] | [ n54.5% n n(2017 est.) n] | [ n n Muslim 99.7% (Sunni 84.... | [ n23.9% n n(2017 est.) n, n22.6% n n(2016 es... | [ ntotal: n19 years n n, nmale: n19 years n n... | . 1 | Albania | [ n0-14 years: n17.84% n(male 287,750 /female ... | [ ntotal: n28,748 sq km n n, nland: n27,398 s... | [ nrevenues: n3.614 billion n n(2017 est.) n, ... | [ n13.2 births/1,000 population n n(2018 est.) n] | [ n6.9 deaths/1,000 population n n(2018 est.) n] | [ n$9.505 billion n n(31 December 2017 est.) n... | [ n$13.07 billion n(2017 est.) n(2017 est.) n] | [ n$12,500 n n(2017 est.) n, n$12,100 n n(201... | [ n2.9 beds/1,000 population n n(2013) n] | [ n1.29 physicians/1,000 population n n(2013) n] | [ ntotal population: n78.6 years n n(2018 est.... | [ nlowest 10%: n19.6% n n(2015 est.) n, nhigh... | [ n3,057,220 n n(July 2018 est.) n] | [ n14.3% n n(2012 est.) n] | [ n n Muslim 56.7%, Roman Cat... | [ n13.8% n n(2017 est.) n, n15.2% n n(2016 es... | [ ntotal: n33.4 years n n, nmale: n32 years n... | . 2 | Algeria | [ n0-14 years: n29.49% n(male 6,290,619 /femal... | [ ntotal: n2,381,740 sq km n n, nland: n2,381... | [ nrevenues: n54.15 billion n n(2017 est.) n, ... | [ n21.5 births/1,000 population n n(2018 est.) n] | [ n4.3 deaths/1,000 population n n(2018 est.) n] | [ n$6.26 billion n n(31 December 2017 est.) n,... | [ n$167.6 billion n(2017 est.) n(2017 est.) n] | [ n$15,200 n n(2017 est.) n, n$15,200 n n(201... | [ n1.9 beds/1,000 population n n(2015) n] | NaN | [ ntotal population: n77.2 years n n(2018 est.... | [ nlowest 10%: n26.8% n n(1995) n, nhighest 1... | [ n41,657,488 n n(July 2018 est.) n] | [ n23% n n(2006 est.) n] | [ n n Muslim (official; predo... | [ n11.7% n n(2017 est.) n, n10.5% n n(2016 es... | [ ntotal: n28.3 years n n, nmale: n28 years n... | . 3 | American Samoa | [ n0-14 years: n29.59% n(male 7,732 /female 7,... | [ ntotal: n224 sq km n n, nland: n224 sq km n... | [ nrevenues: n249 million n n(2016 est.) n, n... | [ n19 births/1,000 population n n(2018 est.) n] | [ n5.9 deaths/1,000 population n n(2018 est.) n] | [ nNA n] | [ n$658 million n(2016 est.) n(2016 est.) n] | [ n$11,200 n n(2016 est.) n, n$11,300 n n(201... | NaN | NaN | [ ntotal population: n73.9 years n n(2018 est.... | [ nlowest 10%: nNA n, nhighest 10%: nNA n] | [ n50,826 n n(July 2018 est.) n] | [ nNA n] | [ n n Christian 98.3%, other ... | [ n29.8% n n(2005) n] | [ ntotal: n26.1 years n n, nmale: n25.6 years... | . 4 | Andorra | [ n0-14 years: n14.06% n(male 6,197 /female 5,... | [ ntotal: n468 sq km n n, nland: n468 sq km n... | [ nrevenues: n1.872 billion n n(2016) n, nexp... | [ n7.3 births/1,000 population n n(2018 est.) n] | [ n7.4 deaths/1,000 population n n(2018 est.) n] | [ n$0 n n(2016) n] | [ n$2.712 billion n(2016 est.) n(2016 est.) n] | [ n$49,900 n n(2015 est.) n, n$51,300 n n(201... | [ n2.5 beds/1,000 population n n(2009) n] | [ n3.69 physicians/1,000 population n n(2015) n] | [ ntotal population: n82.9 years n n(2018 est.... | [ nlowest 10%: nNA n, nhighest 10%: nNA n] | [ n85,708 n n(July 2018 est.) n] | NaN | [ n n Roman Catholic (predom... | [ n3.7% n n(2016 est.) n, n4.1% n n(2015 est.... | [ ntotal: n44.9 years n n, nmale: n45.1 years... | . Age Strucuture . as we can see, we managed to place data in a dataframe, however, it is not quite readable and contains descriptions and a lot of redunduncy that we can remove. We are dividing our data into 4 main tables: . Age structure | Median age | Demographics | Economics | . We will alo rename our columns and structure our data such that its easy and ready for analysis . The apply method applies a transformation along an axis specified, in my opinion it&#39;s one of the most important methods in the pandas library and as you will see, we wil be using it almost in every block of code in order to clean or transform our data. . Age_groups = [&#39;0-14&#39;, &#39;15-24&#39;, &#39;25-54&#39;, &#39;55-64&#39;, &#39;65+&#39;] for i, age in enumerate(Age_groups): df[age+&#39;_male&#39;] = df[&#39;Age structure&#39;].apply(lambda l: re.search(&#39;male d*,? d*,? d*&#39;, str(l[i])) if isinstance(l, list) else float(&#39;Nan&#39;)) df[age+&#39;_female&#39;] = df[&#39;Age structure&#39;].apply(lambda l: re.search(&#39;female d*,? d*,? d*&#39;, str(l[i])) if isinstance(l, list) else float(&#39;Nan&#39;)) # cleaning up and turning into some readable numbers def get_number(reg): if isinstance(reg, re.Match): return float(reg.string[reg.start(): reg.end()].split(&#39; &#39;)[-1].replace(&#39;,&#39;, &#39;&#39;)) else: return float(&#39;nan&#39;) . age_columns = [] for i, age in enumerate(Age_groups): df[age+&#39;_male&#39;] = df[age+&#39;_male&#39;].apply(get_number) df[age+&#39;_female&#39;] = df[age+&#39;_female&#39;].apply(get_number) df[age] = df[age+&#39;_male&#39;] + df[age+&#39;_female&#39;] age_columns += [age+&#39;_male&#39;, age+&#39;_female&#39;] . Frame = pd.melt(df, id_vars=[&#39;Country&#39;] , value_vars=age_columns, var_name=&#39;Category&#39;, value_name=&#39;Population&#39;) . Frame.head() . Country Category Population . 0 | Afghanistan | 0-14_male | 7263716.0 | . 1 | Albania | 0-14_male | 287750.0 | . 2 | Algeria | 0-14_male | 6290619.0 | . 3 | American Samoa | 0-14_male | 7732.0 | . 4 | Andorra | 0-14_male | 6197.0 | . df . Frame[[&#39;Category&#39;, &#39;Sex&#39;]] = Frame[&#39;Category&#39;].str.split(&#39;_&#39;, expand=True) Frame.head() . Country Category Population Sex . 0 | Afghanistan | 0-14 | 7263716.0 | male | . 1 | Albania | 0-14 | 287750.0 | male | . 2 | Algeria | 0-14 | 6290619.0 | male | . 3 | American Samoa | 0-14 | 7732.0 | male | . 4 | Andorra | 0-14 | 6197.0 | male | . len(df) == len(Frame)/5/2 # 5 age cateories and 2 sex cat . True . median_df = df.copy()[[&#39;Country&#39;, &#39;Median age&#39;]] median_df.head() . Country Median age . 0 | Afghanistan | [ ntotal: n19 years n n, nmale: n19 years n n... | . 1 | Albania | [ ntotal: n33.4 years n n, nmale: n32 years n... | . 2 | Algeria | [ ntotal: n28.3 years n n, nmale: n28 years n... | . 3 | American Samoa | [ ntotal: n26.1 years n n, nmale: n25.6 years... | . 4 | Andorra | [ ntotal: n44.9 years n n, nmale: n45.1 years... | . median_df[&#39;median_age&#39;] = median_df[&#39;Median age&#39;].apply(lambda t: float(t[0].split(&#39; n&#39;)[2].split()[0]) if isinstance(t, list) else float(&#39;nan&#39;)) median_df[&#39;median_male&#39;] = median_df[&#39;Median age&#39;].apply(lambda t: float(t[1].split(&#39; n&#39;)[2].split()[0]) if isinstance(t, list) else float(&#39;nan&#39;)) median_df[&#39;median_female&#39;] = median_df[&#39;Median age&#39;].apply(lambda t: float(t[2].split(&#39; n&#39;)[2].split()[0]) if isinstance(t, list) else float(&#39;nan&#39;)) . median_df.drop(&#39;Median age&#39;, axis=1, inplace=True) . median_df.head() . Country median median_male median_female . 0 | Afghanistan | 19.0 | 19.0 | 19.1 | . 1 | Albania | 33.4 | 32.0 | 34.7 | . 2 | Algeria | 28.3 | 28.0 | 28.7 | . 3 | American Samoa | 26.1 | 25.6 | 26.5 | . 4 | Andorra | 44.9 | 45.1 | 44.8 | . More Demographics by Country . demo = [&#39;Area&#39;,&#39;Birth rate&#39;, &#39;Death rate&#39;, &#39;Hospital bed density&#39;,&#39;Physicians density&#39;, &#39;Life expectancy at birth&#39;,&#39;Population below poverty line&#39;,&#39;Unemployment rate&#39;] . for c in demo: df[c] = df[c].apply(lambda l: l[0].replace(&#39; n&#39;, &#39;&#39;) if isinstance(l , list) else float(&#39;nan&#39;)) . demo_df = df.copy()[demo] demo_df.head() . Area Birth rate Death rate Hospital bed density Physicians density Life expectancy at birth Population below poverty line Unemployment rate . 0 | total:652,230 sq km | 37.5 births/1,000 population(2018 est.) | 13.2 deaths/1,000 population(2018 est.) | 0.5 beds/1,000 population(2014) | 0.3 physicians/1,000 population(2016) | total population:52.1 years(2018 est.) | 54.5%(2017 est.) | 23.9%(2017 est.) | . 1 | total:28,748 sq km | 13.2 births/1,000 population(2018 est.) | 6.9 deaths/1,000 population(2018 est.) | 2.9 beds/1,000 population(2013) | 1.29 physicians/1,000 population(2013) | total population:78.6 years(2018 est.) | 14.3%(2012 est.) | 13.8%(2017 est.) | . 2 | total:2,381,740 sq km | 21.5 births/1,000 population(2018 est.) | 4.3 deaths/1,000 population(2018 est.) | 1.9 beds/1,000 population(2015) | NaN | total population:77.2 years(2018 est.) | 23%(2006 est.) | 11.7%(2017 est.) | . 3 | total:224 sq km | 19 births/1,000 population(2018 est.) | 5.9 deaths/1,000 population(2018 est.) | NaN | NaN | total population:73.9 years(2018 est.) | NA | 29.8%(2005) | . 4 | total:468 sq km | 7.3 births/1,000 population(2018 est.) | 7.4 deaths/1,000 population(2018 est.) | 2.5 beds/1,000 population(2009) | 3.69 physicians/1,000 population(2015) | total population:82.9 years(2018 est.) | NaN | 3.7%(2016 est.) | . Area (km^2) &amp; Life expectancy at birth . area = demo_df[&#39;Area&#39;].apply(lambda x: (x.split(&#39;:&#39;)[1].split(&#39; &#39;)[0]).replace(&#39;,&#39;,&#39;&#39;)) area.at[243] = 439781 #French Southern and Antarctic Lands&#39; demo_df[&#39;Area&#39;] = area.astype(float) . def get_exp(c): try: return float((c.split(&#39;:&#39;)[1].split(&#39; &#39;)[0]).replace(&#39;,&#39;,&#39;&#39;)) except: return float(&#39;nan&#39;) life_exp = df[&#39;Life expectancy at birth&#39;].apply(get_exp) demo_df[&#39;Life expectancy at birth&#39;] = life_exp.astype(float) . demo_df . Area Birth rate Death rate Hospital bed density Physicians density Life expectancy at birth Population below poverty line Unemployment rate . 0 | 652230.00 | 37.5 births/1,000 population(2018 est.) | 13.2 deaths/1,000 population(2018 est.) | 0.5 beds/1,000 population(2014) | 0.3 physicians/1,000 population(2016) | 52.1 | 54.5%(2017 est.) | 23.9%(2017 est.) | . 1 | 28748.00 | 13.2 births/1,000 population(2018 est.) | 6.9 deaths/1,000 population(2018 est.) | 2.9 beds/1,000 population(2013) | 1.29 physicians/1,000 population(2013) | 78.6 | 14.3%(2012 est.) | 13.8%(2017 est.) | . 2 | 2381740.00 | 21.5 births/1,000 population(2018 est.) | 4.3 deaths/1,000 population(2018 est.) | 1.9 beds/1,000 population(2015) | NaN | 77.2 | 23%(2006 est.) | 11.7%(2017 est.) | . 3 | 224.00 | 19 births/1,000 population(2018 est.) | 5.9 deaths/1,000 population(2018 est.) | NaN | NaN | 73.9 | NA | 29.8%(2005) | . 4 | 468.00 | 7.3 births/1,000 population(2018 est.) | 7.4 deaths/1,000 population(2018 est.) | 2.5 beds/1,000 population(2009) | 3.69 physicians/1,000 population(2015) | 82.9 | NaN | 3.7%(2016 est.) | . ... | ... | ... | ... | ... | ... | ... | ... | ... | . 262 | 5.00 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 263 | 62045.00 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 264 | 12.00 | NaN | NaN | NaN | 2.72 physicians/1,000 population(2010) | NaN | NA | NA | . 265 | 6959.41 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 266 | 6.50 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 267 rows × 8 columns . Birth Rate, Death rate, Physicians density, Hospital bed density, Population below poverty line and Unemployment rate . section1 = [&#39;Birth rate&#39;, &#39;Death rate&#39;, &#39;Hospital bed density&#39;,&#39;Physicians density&#39;] . for s in section1: demo_df[s] = demo_df[s].map(lambda x: float(x.split(&#39; &#39;)[0]) if isinstance(x, str) else float(&#39;nan&#39;)) . section2 = [&#39;Population below poverty line&#39;, &#39;Unemployment rate&#39;] def clean_perc(c): try: return float(c.split(&#39;%&#39;)[0]) except: return float(&#39;nan&#39;) for s in section2: demo_df[s] = demo_df[s].apply(clean_perc) . demo_df.index = df[&#39;Country&#39;] . GDP and Budget by Country . selection = [&#39;Country&#39;, &#39;Budget&#39;, &#39;Debt - external&#39;, &#39;GDP (official exchange rate)&#39;, &#39;GDP - per capita (PPP)&#39;] eco_df = df.copy()[selection] . Country Budget Debt - external GDP (official exchange rate) GDP - per capita (PPP) . 0 | Afghanistan | [ nrevenues: n2.276 billion n n(2017 est.) n, ... | [ n$2.84 billion n n(FY/) n] | [ n$20.24 billion n(2017 est.) n(2017 est.) n] | [ n$2,000 n n(2017 est.) n, n$2,000 n n(2016 ... | . 1 | Albania | [ nrevenues: n3.614 billion n n(2017 est.) n, ... | [ n$9.505 billion n n(31 December 2017 est.) n... | [ n$13.07 billion n(2017 est.) n(2017 est.) n] | [ n$12,500 n n(2017 est.) n, n$12,100 n n(201... | . 2 | Algeria | [ nrevenues: n54.15 billion n n(2017 est.) n, ... | [ n$6.26 billion n n(31 December 2017 est.) n,... | [ n$167.6 billion n(2017 est.) n(2017 est.) n] | [ n$15,200 n n(2017 est.) n, n$15,200 n n(201... | . 3 | American Samoa | [ nrevenues: n249 million n n(2016 est.) n, n... | [ nNA n] | [ n$658 million n(2016 est.) n(2016 est.) n] | [ n$11,200 n n(2016 est.) n, n$11,300 n n(201... | . 4 | Andorra | [ nrevenues: n1.872 billion n n(2016) n, nexp... | [ n$0 n n(2016) n] | [ n$2.712 billion n(2016 est.) n(2016 est.) n] | [ n$49,900 n n(2015 est.) n, n$51,300 n n(201... | . def extract_budget(l, i): try: return l[i].split(&#39; n&#39;)[2] except: return float(&#39;nan&#39;) eco_df[&#39;Revenues($)&#39;] = eco_df[&#39;Budget&#39;].map(lambda t: extract_budget(t, 0)) eco_df[&#39;Expenditures($)&#39;] = eco_df[&#39;Budget&#39;].map(lambda t: extract_budget(t, 1)) . eco_df[&#39;Debt_ext($)&#39;] = eco_df[&#39;Debt - external&#39;].map(lambda t: t[0].split(&#39; n&#39;)[1] if isinstance(t, list) else float(&#39;nan&#39;)) eco_df[&#39;GDP($)&#39;] = eco_df[&#39;GDP (official exchange rate)&#39;].map(lambda t: t[0].split(&#39; n&#39;)[1] if isinstance(t, list) else float(&#39;nan&#39;)) eco_df[&#39;GDP_per_Capita($)&#39;] = eco_df[&#39;GDP - per capita (PPP)&#39;].map(lambda t: t[0].split(&#39; n&#39;)[1] if isinstance(t, list) else float(&#39;nan&#39;)) . eco_df.drop([&#39;Budget&#39;, &#39;Debt - external&#39;, &#39;GDP (official exchange rate)&#39;, &#39;GDP - per capita (PPP)&#39;] , axis=1, inplace=True) . eco_df.head() . Country Revenues($) Expenditures($) Debt_ext($) GDP($) GDP_per_Capita($) . 0 | Afghanistan | 2.276 billion | 5.328 billion | $2.84 billion | $20.24 billion | $2,000 | . 1 | Albania | 3.614 billion | 3.874 billion | $9.505 billion | $13.07 billion | $12,500 | . 2 | Algeria | 54.15 billion | 70.2 billion | $6.26 billion | $167.6 billion | $15,200 | . 3 | American Samoa | 249 million | 262.5 million | NA | $658 million | $11,200 | . 4 | Andorra | 1.872 billion | 2.06 billion | $0 | $2.712 billion | $49,900 | . def clean_fig(e, mode=1): try: l = e.split(&#39; &#39;) if mode == 1: num = float(l[0].replace(&#39;,&#39;, &#39;&#39;)) else: num = float(l[0][1:].replace(&#39;,&#39;, &#39;&#39;)) if len(l) == 1: return num else: return num * 1e6 if l[1].strip() == &#39;million&#39; else num * 1e9 except: return float(&#39;nan&#39;) . eco_df[&#39;Revenues($)&#39;] = eco_df[&#39;Revenues($)&#39;].apply(clean_fig) eco_df[&#39;Expenditures($)&#39;] = eco_df[&#39;Expenditures($)&#39;].apply(clean_fig) eco_df[&#39;Debt_ext($)&#39;] = eco_df[&#39;Debt_ext($)&#39;].apply(lambda t: clean_fig(t, 2)) eco_df[&#39;GDP($)&#39;] = eco_df[&#39;GDP($)&#39;].apply(lambda t: clean_fig(t, 2)) eco_df[&#39;GDP_per_Capita($)&#39;] = eco_df[&#39;GDP_per_Capita($)&#39;].apply(lambda t: clean_fig(t, 2)) . eco_df.head(5) . Country Revenues($) Expenditures($) Debt_ext($) GDP($) GDP_per_Capita($) . 0 | Afghanistan | 2.276000e+09 | 5.328000e+09 | 2.840000e+09 | 2.024000e+10 | 2000.0 | . 1 | Albania | 3.614000e+09 | 3.874000e+09 | 9.505000e+09 | 1.307000e+10 | 12500.0 | . 2 | Algeria | 5.415000e+10 | 7.020000e+10 | 6.260000e+09 | 1.676000e+11 | 15200.0 | . 3 | American Samoa | 2.490000e+08 | 2.625000e+08 | NaN | 6.580000e+08 | 11200.0 | . 4 | Andorra | 1.872000e+09 | 2.060000e+09 | 0.000000e+00 | 2.712000e+09 | 49900.0 | . Overview so far . Frame.sample(n=10) . Country Category Population Sex . 955 | Norway | 15-24 | 324088.0 | female | . 1867 | United States Pacific Island Wildlife Refuges | 55-64 | NaN | male | . 945 | Namibia | 15-24 | 257984.0 | female | . 1028 | World | 15-24 | 572229547.0 | female | . 492 | West Bank | 0-14 | 491676.0 | female | . 577 | Christmas Island | 15-24 | 202.0 | male | . 2475 | France | 65+ | 7569011.0 | female | . 1373 | Cayman Islands | 25-54 | 12855.0 | female | . 421 | Norway | 0-14 | 471014.0 | female | . 2204 | European Union | 65+ | 43673572.0 | male | . Frame.to_csv(&#39;clean_CIA_data/Age_structure.csv&#39;) . median_df.sample(n=10) . Country median median_male median_female . 201 | Tajikistan | 24.8 | 24.2 | 25.4 | . 23 | Bhutan | 28.1 | 28.6 | 27.6 | . 207 | Trinidad and Tobago | 36.6 | 36.1 | 37.1 | . 184 | Sierra Leone | 19.1 | 18.4 | 19.7 | . 213 | Uganda | 15.9 | 15.8 | 16.0 | . 70 | Fiji | 29.2 | 29.0 | 29.4 | . 101 | Israel | 30.1 | 29.5 | 30.7 | . 144 | Namibia | 21.4 | 20.7 | 22.2 | . 10 | Aruba | 39.5 | 37.8 | 41.2 | . 3 | American Samoa | 26.1 | 25.6 | 26.5 | . median_df.to_csv(&#39;clean_CIA_data/median_age_country.csv&#39;) . demo_df = demo_df.rename(columns={&#39;Area&#39;: &#39;Area(km^2)&#39;, &#39;Birth rate&#39;: &#39;Birth_rate_per_1000&#39;, &#39;Death rate&#39;: &#39;Birth_rate_per_1000&#39;, &#39;Hospital bed density&#39;: &#39;Hospital_bed_density_per_1000&#39;, &#39;Life expectancy at birth&#39;: &#39;Life_expec_at_birth&#39;, &#39;Physicians density&#39;: &#39;Physicians_density_per_1000&#39;, &#39;Population below poverty line&#39;: &#39;Percentage_below_poverty_line&#39;, &#39;Unemployment rate&#39;: &#39;Unemployment_rate_%&#39;}) . demo_df.sample(n=10) . Area(km^2) Birth_rate_per_1000 Birth_rate_per_1000 Hospital_bed_density_per_1000 Physicians_density_per_1000 Life_expec_at_birth Percentage_below_poverty_line Unemployment_rate_% . Country . South Sudan | 644329.0 | 36.9 | 19.3 | NaN | NaN | NaN | 66.0 | NaN | . Western Sahara | 266000.0 | 28.9 | 7.9 | NaN | NaN | 63.8 | NaN | NaN | . Saint Vincent and the Grenadines | 389.0 | 13.0 | 7.4 | 2.6 | NaN | 75.8 | NaN | 18.8 | . Panama | 75420.0 | 17.6 | 5.0 | 2.3 | 1.59 | 78.9 | 23.0 | 6.0 | . Malta | 316.0 | 10.0 | 7.9 | 4.7 | 3.91 | 82.7 | 16.3 | 4.6 | . Wallis and Futuna | 142.0 | 13.0 | 5.5 | NaN | 1.10 | 80.0 | NaN | 8.8 | . Denmark | 43094.0 | 10.9 | 9.3 | 2.5 | 3.66 | 81.0 | 13.4 | 5.7 | . Kiribati | 811.0 | 21.0 | 7.0 | 1.9 | 0.20 | 66.9 | NaN | 30.6 | . Greece | 131957.0 | 8.3 | 11.4 | 4.3 | 6.26 | 80.8 | 36.0 | 21.5 | . Zambia | 752618.0 | 41.1 | 12.0 | 2.0 | 0.09 | 53.0 | 54.4 | 15.0 | . demo_df.to_csv(&#39;clean_CIA_data/country_data.csv&#39;) . eco_df.index = eco_df[&#39;Country&#39;]; eco_df.drop(&#39;Country&#39;, axis=1, inplace=True) eco_df.sample(n=10) . Revenues($) Expenditures($) Debt_ext($) GDP($) GDP_per_Capita($) . Country . Uganda | 3.848000e+09 | 4.928000e+09 | 1.080000e+10 | 2.662000e+10 | 2400.0 | . Jan Mayen | NaN | NaN | NaN | NaN | NaN | . Belize | 5.535000e+08 | 5.720000e+08 | 1.315000e+09 | 1.854000e+09 | 8300.0 | . Bahrain | 5.854000e+09 | 9.407000e+09 | 5.215000e+10 | 3.533000e+10 | 49000.0 | . Honduras | 4.658000e+09 | 5.283000e+09 | 8.625000e+09 | 2.298000e+10 | 5600.0 | . Kyrgyzstan | 2.169000e+09 | 2.409000e+09 | 8.164000e+09 | 7.565000e+09 | 3700.0 | . Jordan | 9.462000e+09 | 1.151000e+10 | 2.934000e+10 | 4.013000e+10 | 9200.0 | . Mongolia | 2.967000e+09 | 3.681000e+09 | 2.533000e+10 | 1.114000e+10 | 13000.0 | . Sweden | 2.712000e+11 | 2.644000e+11 | 9.399000e+11 | 5.356000e+11 | 51200.0 | . Solomon Islands | 5.325000e+08 | 5.705000e+08 | 7.570000e+08 | 1.298000e+09 | 2200.0 | . eco_df.to_csv(&#39;clean_CIA_data/eco_overview.csv&#39;) . Conclusion . Now you are ready to analyze the world factbook data. We have went over a bunch of techniques and libraries to help us scrape a web page: . BeautifulSoup: parse HTML content and get fields we need | pandas: structure the data and apply manipulation | re: regular expression library to helps us clean data | . in addition we can use requests to import the HTML content. . Hopefully this guided code provided you with an idea on how you can apply the same to your own. .",
            "url": "https://yassine-mhedhbi.github.io/YassBlog/tutorial/jupyter/pandas/beautifulsoup/spy/2020/05/21/Scraping-CIA-Data.html",
            "relUrl": "/tutorial/jupyter/pandas/beautifulsoup/spy/2020/05/21/Scraping-CIA-Data.html",
            "date": " • May 21, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Yassine Mhedhbi and I am currently an AI solution Developer at Deloitte Omnia. I pursued a joint major in Mathematics and Computer Science at McGill University, a public research university in Montreal, Quebec, Canada from 2015 to 2019. I’m interested in deep learning and its application in computer vision, robotics and NLP. . I’m an Ex professional Taekwondo player and I enjoy playing soccer in my spare time. I love travelling and discovering new cultures. . Education . Bachelor in Science, Majoring in Math &amp; Comp sci . Sep 2015 ~ April 2019 . Research Experience:   May 2018 ~ Dec 2018 . Working under the supervision of Professor David Meger in the Mobile Robotics lab | Exploring arm robot actions using auditory input i.e. noise resulting from robot-environment interaction | Developing tools to catch audio and get instant feedback | . Relevant courses taken: . COMP 251 : Algorithms and Data structures | COMP 302 : Programming lanuages and paradigms | MATH 236 : Algebra II, (Linear Algebra) | MATH 356 : Honours Probability | COMP 360 : Algorithm Design | COMP 551 : Mathematical Foundations Of Machine Learning | MATH 560 : Optimization | MATH 523 : Generalized Linear Models | . Grading: . Math 235: Algebra I (Fall 2017) | MATH 236: Algebra II, (Linear Algebra) | Math 223: Linear Algebra | . Work experience: . Omnia Ai | Deloitte’s AI practice: . Solution Designer . August 2019 ~ . Nuance Communcations: . Dialog Developer Intern: . May 2018 ~ August 2018 . Software product development in C++ for customers using Nuance’s Dragon Drive framework | Developing part of a demo application to test the system function blocks | Took part in developing a graphical user interface to test the system functionality using Java, JavaScript, JQuery and React | . Dialog Developer Intern: . May 2017 ~ August 2017 . Software product development in C++ for customers using Nuance’s Dragon Drive framework | Development of scripts to accelerate the release process using Python 2.7 using FogBugz API | Updating the Visio documents to match the current code flow of the system | .",
          "url": "https://yassine-mhedhbi.github.io/YassBlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://yassine-mhedhbi.github.io/YassBlog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}